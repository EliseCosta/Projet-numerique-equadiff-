{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet numérique 2 : choix du pas de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Philomène Blot\n",
    "\n",
    "Elise Costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pas fixe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un schéma de type Euler explicite est de la forme :\n",
    "    $x^{j+1} = x^j + \\Delta t f(t_j, x^j))$ si $\\dot x(t)) = f(t,x(t))$.\n",
    "    \n",
    "On l'implémente en python ci-dessous, en prenant garde à utiliser numpy car l'équation différentielle à résoudre à sûrement été réduite à l'ordre 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def solve_euler_explicit(f,x0,dt,t0=0.0, tf = 3) :\n",
    "    t_j = [t0]\n",
    "    x_j = [x0]\n",
    "    while t_j[-1] + dt <= tf :\n",
    "        x_i = x_j[-1]+ dt*f(t_j[-1], x_j[-1])\n",
    "        x_j.append(x_i)\n",
    "        t_i = t_j[-1] + dt\n",
    "        t_j.append(t_i)\n",
    "    return (np.array(t_j), np.array(x_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notre équation à résoudre\n",
    "\n",
    "On veut résoudre l'équation : $y''+ y = 0$.  On pose :\n",
    "$\n",
    "x = \n",
    "\\begin{pmatrix}\n",
    "y \\\\\n",
    "y' \\\\\n",
    "\\end{pmatrix}\n",
    "$ pour revenir à l'ordre 1.\n",
    "\n",
    "On a alors $x' = \n",
    "\\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "-1 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "x\n",
    "$\n",
    "\n",
    "Si la condition initiale vaut\n",
    "$\n",
    "x_{0} = \n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "\\end{pmatrix}\n",
    "$,\n",
    "alors $ y = cos $.\n",
    "\n",
    "Vérifions que algorithme ne s'éloigne pas trop du résulat réel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test1\n",
    "\n",
    "A = np.array([[0,1],[-1,0]])\n",
    "x0 = np.array([[1.0],[0.0]])\n",
    "\n",
    "\n",
    "def f(t,x) : \n",
    "    return np.dot(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1,X1 = solve_euler_explicit(f,x0,10**(-4))\n",
    "\n",
    "T1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithme de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à trouver le maximum de $\\| x^j - x(t_j) \\|$ pour certains pas en puissance. Une fois ce maximum déterminé, on le divise par $\\Delta t$ (on ne divise que le maximum pour la complexité). On trace en fonction du pas $max\\frac{\\| x^j - x(t_j) \\|}{\\Delta t^2} $ et on essaye d'intuiter ce qui se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste de dt à tester\n",
    "t = [10**(-i) for i in range(5,0,-1)]\n",
    "\n",
    "# trouver le maximum pour g méthode de résolution\n",
    "def intuiter_cs() :\n",
    "    Lmaxi = []\n",
    "    for dt in t :\n",
    "        T, X = solve_euler_explicit(f,x0,dt)\n",
    "        m = [abs(X[i][0][0]-cos(T[i])) for i in range(len(T))]\n",
    "        maxi = max(m)/dt\n",
    "        Lmaxi.append(maxi)\n",
    "    plt.scatter(t,Lmaxi)\n",
    "    \n",
    "intuiter_cs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble que $\\frac{\\| x^j - x(t_j) \\|}{\\Delta t} $ soit bornée par 1,495 environ. Le schéma semble bien convergent à l'ordre 1. Cela est d'ailleurs vrai par théorème de Lax : Euler explicite est consistant d'ordre 1 et stable par condition suffisante pour la stabilité ($f$ est $C^1$ par rapport à $x$ donc localement lipschitzienne par rapport à $x$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pourquoi la méthode de Heun est d'ordre deux (pour la consistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compare avec la méthode de Heun qui est d'ordre deux pour la consistance.\n",
    "\n",
    "Heun est défini par : $x^{j+1} = x^j + \\frac{\\Delta t}{2}[f(t_{j+1}, x^{t_j}) + f(t_{j+1}, x^j + \\Delta t f(t_{j+1}, x^{t_j}))]$\n",
    "\n",
    "Ainsi, pour Heun : $\\boxed{\\eta^{j+1} = \\frac{x(t(j+1) - x(t(j) - \\frac{\\Delta t}{2}[f(t_{j+1}, x(t_j)) + f(t_{j+1}, x(t_j) + \\Delta t f(t_{j+1}, x(t_j)))]}{\\Delta t}}$\n",
    "\n",
    "Or, comme $\\dot{x}(t) = f(t, x(t)) $ et que $f$ est $C^1$ alors x est $C^2$. Ainsi :\n",
    "\n",
    "$x(t_{j+1}) = x(t_j) + \\Delta t f(t_j, x(t_j)) + \\frac{\\Delta t^2}{2} \\ddot x (t_{j+1}) + O({\\Delta {t^{3}}})$\n",
    "\n",
    "Par règle de la chaîne, on obtient finalement :\n",
    "\n",
    "$\\boxed {x(t_{j+1}) = x(t_j) + \\Delta t f(t_j, x(t_j)) + \\frac{\\Delta t^2}{2} [\\frac{\\partial f}{\\partial t}(t_{j},x(t_{j})) + f(t_{j},x(t_{j}))\\frac{\\partial f}{\\partial x}(t_{j},x(t_{j})))] + O({\\Delta {t^{3}}})}$\n",
    "\n",
    "Par ailleurs :\n",
    "\n",
    "$\\boxed {f(t_{j+1}, x(t_j) + \\Delta t f(t_{j+1}, x(t_j))) = f(t_j, x(t_j)) + \\Delta t [\\frac{\\partial f}{\\partial t}(t_{j},x(t_{j})) + f(t_{j},x(t_{j}))\\frac{\\partial f}{\\partial x}(t_{j},x(t_{j})))] ++ O({\\Delta {t^{2}}})}$\n",
    "\n",
    "En combinant les trois encadrés : $\\color{red}{\\boxed {\\eta^{j+1} = O(\\Delta t^2)}}$, i.e. la méthode de Heun est d'ordre 2 pour la consistance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_heun(f,x0,dt,t0=0.0, tf = 3) :\n",
    "    t_j = [t0]\n",
    "    x_j = [x0]\n",
    "    while t_j[-1] + dt <= tf :\n",
    "        x_i = x_j[-1]+ dt*( f(t_j[-1], x_j[-1]) + f(t_j[-1]+dt, x_j[-1] + dt*f(t_j[-1], x_j[-1])))/2\n",
    "        x_j.append(x_i)\n",
    "        t_i = t_j[-1] + dt\n",
    "        t_j.append(t_i)\n",
    "    return (np.array(t_j), np.array(x_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "T2,X2 = solve_heun(f,x0,10**(-5), 0.0, 1.0)\n",
    "\n",
    "# la méthode est bien implémentée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algotithme de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suit le même schéma que précédemment.\n",
    "\n",
    "On cherche à trouver le maximum de $\\| x^j - x(t_j) \\|$ pour certains pas en puissance. Une fois ce maximum déterminé, on le divise par $\\Delta t^2$ car ici, on veut tester la convergence à l'ordre 2. On trace en fonction du pas $max\\frac{\\| x^j - x(t_j) \\|}{\\Delta t^2} $ et on essaye d'intuiter ce qui se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = [10**(-i) for i in range(5,0,-1)]\n",
    "\n",
    "def intuiter_cs_2() :\n",
    "    Lmaxi = []\n",
    "    for dt in t :\n",
    "        T, X = solve_heun(f,x0,dt)\n",
    "        m = [abs(X[i][0][0]-cos(T[i])) for i in range(len(T))]\n",
    "        maxi = max(m)/(dt**2)\n",
    "        Lmaxi.append(maxi)\n",
    "    plt.scatter(t,Lmaxi)\n",
    "    \n",
    "intuiter_cs_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble que $\\frac{\\| x^j - x(t_j) \\|}{\\Delta t^2} $ soit bornée par 0,33 environ. Le schéma semble bien convergent d'ordre 2. Son ordre de convergence est donc plus élevé que celui d'Euler explicite : cette méthode fournira des résultats plus fins que ceux d'Euler explicite.\n",
    "\n",
    "Heun est bien convergent à l'ordre 2 par théorème de Lax : Euler explicite est consistant à l'ordre 2 et stable par condition suffisante pour la stabilité (montrée en exercice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation au pas de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.3\n",
    "\n",
    "$\\tilde{x}(t_{j+1})$ = $e^{j+1} + x^{j+1}$ $(*)$\n",
    "\n",
    "D'après la définition de  et f étant $C^1$ d'après l'énoncé, $\\tilde{x}$ est de classe $C^2$.\n",
    "\n",
    "On effectue donc un DL à l'ordre 2 de $\\tilde{x}$  en $t_{j+1}$ :\n",
    "\n",
    "$\\tilde{x}(t_{j+1})$ = $\\tilde{x}$ $(t_{j} + \\Delta t)$\n",
    "                     = $\\tilde{x}$$(t_{j})$ + $ \\Delta {t}$$\\dot {\\tilde{x}}$$(t_{j})$ + $ \\Delta {t^{2}}$$\\ddot {\\tilde{x}}$$(t_{j})$× $\\frac{1}{2}$+$\\omicron ({\\Delta {t^{2}}})$   $(**)$\n",
    "                    \n",
    "\n",
    "Comme on suit un schéma d'Euler explicite d'ordre 1, on a la relation suivante :\n",
    "\n",
    "$x^{j} - x^{j+1}$ = - $\\Delta t$$f(t_{j},x^{j})$\n",
    "\n",
    "On a également :\n",
    "\n",
    "$\\tilde{x}(t_{j})$ = $x^{j}$\n",
    "et\n",
    "\n",
    "$\\dot {\\tilde{x}}$$(t_{j})$ = $ f(t_{j}, \\tilde{x}(t_{j}))$\n",
    "\n",
    "En combinant les trois dernières équations avec\n",
    "$(*)$ et $(**)$ , on obtient :\n",
    "\n",
    "$ {e^{j+1}}$ = $\\Delta {t^{2}}$($\\frac{\\partial f}{\\partial t}$$(t_{j}$$,x^{j})$ + $f(t_{j},x^{j})$$\\frac{\\partial f}{\\partial x}$$(t_{j}$$,x^{j})$)×$\\frac{1}{2}$ + $\\omicron ({\\Delta {t}})$\n",
    "\n",
    "Comme f est classe $C^1$, on peut effectuer un DL à l'ordre 1 de f en $(t_{j+1}$$,x^{j+1})$ :\n",
    "\n",
    "$\\Delta t$$\\frac{\\partial f}{\\partial t}$$(t_{j}$$,x^{j})$ + $\\Delta t$$f(t_{j},x^{j})$$\\frac{\\partial f}{\\partial x}$$(t_{j}$$,x^{j})$ = $f(t_{j+1}$$,x^{j+1})$ - $f(t_{j}$$,x^{j})$ + $\\omicron ({\\Delta {t}})$ $(****)$\n",
    "\n",
    "En multipliant $(****)$ par $\\Delta {t}$× $\\frac{1}{2}$, on a en combinant avec $(***)$ :\n",
    "\n",
    "\n",
    "${e^{j+1}}$ = $\\Delta t$$(f(t_{j+1}$$,x^{j+1})$ - $f(t_{j}$$,x^{j}))$×$\\frac{1}{2}$ + $\\omicron ({\\Delta {t^{2}}})$\n",
    "\n",
    "En passant au module, on obtient donc la formule souhaitée :\n",
    "\n",
    "$\\color{red}{\\boxed {\\| e^{j+1}\\| = \\| {\\Delta t(f(t_{j+1},x^{j+1}) - f(t_{j},x^{j}))×\\frac{1}{2}}\\| + Ο(\\Delta {t^{3}})}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.4\n",
    "\n",
    "On a définit $\\tilde{x}(t_j) = x^j $. On est donc dans le cas $e^{j+1} = \\Delta t_{j} \\ \\eta^{j+1}$.\n",
    "\n",
    "Or, le schéma d'Euler explicite est consistant d'ordre 1. Ainsi, il existe $c_s$ une constante telle que, pour tout $ 0 \\ \\le \\ j \\ \\le \\ J-1$ : $\\| \\eta^{j+1} \\| \\le c_s \\Delta t_{j} $ donc a fortiori :  $\\| \\eta^{j+1} \\| = \\mathrm{O} (c_s \\Delta t_{j}) = \\mathrm{O} (\\Delta t_{j}) $. Ainsi : $\\boxed{e^{j+1} = \\mathrm{O} ((\\Delta t_{j})^2)}$.\n",
    "\n",
    "$[1]$ Si $\\| e^{j+1} \\| > Tol_{abs} $, notre programme n'accepte pas l'erreur commise car elle est considérée comme trop importante. Le programme va donc chercher à déterminer un pas plus petit telle que l'erreur (absolue) locale correspondante soit inférieure ou égale à $Tol_{abs}$. Le pas doit en effet être forcément plus petit pour que l'on se rapproche des conditions où la linéarisation donne un résultat plus proche de la valeur réelle. Or $\\Delta t_{new} < \\Delta t_{j}$ par construction de $\\Delta t_{new}$ si $\\| e^{j+1} \\| > Tol_{abs} $ ce qui est rassurant.\n",
    "\n",
    "Plus précisément :\n",
    "\n",
    "On sait que $e^{j+1} = \\mathrm{O} ((\\Delta t_{j})^2)$ donc $ \\sqrt{\\|e^{j+1}\\|} = \\mathrm{O} (\\Delta t_{j}) \\ \\ [*]$.\n",
    "\n",
    "Or, on voudrait que le nouveau pas $\\Delta t_{new}$ soit tel que $ \\sqrt{\\|e^{new}\\|} \\le \\sqrt{Tol_{abs}}$. On choisit : $ \\sqrt{\\|e^{new}\\|} = \\sqrt{Tol_{abs}}$.\n",
    "\n",
    "$[*]$ donne : il existe $h$ fonction bornée au voisinage telle que $\\sqrt{\\|e^{X}\\|} = h(\\Delta t_{X}) \\Delta t_{}$. En première approximation, si on considère que les variations de h sont faibles, on a : $ \\frac{\\sqrt{\\|e^{j+1}\\|}}{(\\Delta t_{j})} = \\frac{\\sqrt{\\|e^{new}\\|}}{(\\Delta t_{new})} = \\frac{\\sqrt{Tol_{abs}}}{(\\Delta t_{new})}$.\n",
    "\n",
    "On a donc bien, en posant $ \\Delta t_{j} = \\Delta t $ : $\\color{red}{\\boxed{ \\Delta t_{new} = \\Delta t \\sqrt{\\frac{ Tol_{abs}}{\\|e^{j+1}\\|}}}}$.\n",
    "\n",
    "On peut de plus affiner ce résultat en multipliant  $ \\Delta t_{new} $ par $C$ une constante appartenant à $\\left]0,1\\right[$ qui ne soit pas trop faible pour ne pas ralentir le programmme. On peut penser que $ C = \\frac{1}{2} $ est un bon compromis.\n",
    "\n",
    "$[2]$ Si $\\| e^{j+1} \\| < Tol_{abs} $, une stratégie analogue nous permet d'augmenter  $ \\Delta t_{new} $.\n",
    "\n",
    "$[3]$ Si $\\| e^{j+1} \\| = Tol_{abs} $, $ \\Delta t_{new} $ vaut $ \\Delta t $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ivp_euler_explicit_variable_step(f, t0, x0, t_f, dtmin = 1e-16, dtmax = 0.01, atol = 1e-6):\n",
    "    dt = dtmax/10; # initial integration step\n",
    "    ts, xs = [t0], [x0]  # storage variables\n",
    "    t = t0\n",
    "    ti = 0  # internal time keeping track of time since latest storage point : must remain below dtmax\n",
    "    x = x0\n",
    "    while ts[-1] < t_f:\n",
    "        while ti < dtmax: # on veut avoir un pas plus grand\n",
    "            t_next, ti_next, x_next = t + dt, ti + dt, x + dt * f(x)\n",
    "            x_back = x_next - dt * f(x_next)\n",
    "            ratio_abs_error = atol / (linalg.norm(x_back-x)/2)\n",
    "            dt = 0.9 * dt * sqrt(ratio_abs_error)\n",
    "            if dt < dtmin:\n",
    "                raise ValueError(\"Time step below minimum\")\n",
    "            elif dt > dtmax/2:\n",
    "                dt = dtmax/2\n",
    "            t, ti, x = t_next, ti_next, x_next\n",
    "        dt2DT = dtmax - ti # time left to dtmax\n",
    "        t_next, ti_next, x_next = t + dt2DT, 0, x + dt2DT * f(x)\n",
    "        ts = vstack([ts,t_next])\n",
    "        xs = vstack([xs,x_next])\n",
    "        t, ti, x = t_next, ti_next, x_next\n",
    "    return (ts, xs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend un argument une fonction $f$ telle que $\\dot {x} = f(t,x(t))$, des conditions initiales $t_0$ et $x_0$, et finale $t_f$. Mais ici, on va chercher à calculer des points intermédiaires entre les valeurs du pas $dtmax$ afin de rester le plus proche possible de la vraie solution.\n",
    "\n",
    "Ces valeurs intermédiaires ne seront pas ajoutées dans la liste afin de ne pas trop augmenter la complexité en mémoire.\n",
    "\n",
    "Pour calculer les points intermédiaires, on adapte le pas avec la méthode définie ci-dessus. La norme de $\\|e^{j+1}\\|$ est calculée à l'aide de l'expression : $ \\| e^{j+1}\\| = \\| {\\Delta t(f(t_{j+1},x^{j+1}) - f(t_{j},x^{j}))×\\frac{1}{2}}\\| + Ο(\\Delta {t^{3}}) $ que l'on approxime par $\\| e^{j+1}\\| = \\| {\\Delta t(f(t_{j+1},x^{j+1}) - f(t_{j},x^{j}))×\\frac{1}{2}}\\|$. Des sécurités sont de plus ajoutées pour affiner ce parcours intermédiaire : on multiplie l'expression du nouveau pas intermédiaire par $0.9$, si ce pas intermédiaire est plus petit que $dtmin$, on arrête le programme afin d'éviter qu'il tourne en faisant du sur-place ou presque, et si le pas est trop grand (ici plus grand strictement que $\\frac{dtmax}{2}$), alors on le limite à $\\frac{dtmax}{2}$.\n",
    "\n",
    "A partir du moment où les calculs intermédiaires parcourent une largeur $dtmax$, on souhaite stocker la valeur en $ts[-1] + dtmax$. Pour se faire, on calcule $dt2DT$ qui est distance (négative ou nulle) qui nous sépare de $ts[-1] + dtmax$. On calcule alors la valeur de $x$ correspondant. On complète alors $ts$ et $xs$.\n",
    "\n",
    "On itère ce processus jusqu'à ce que l'on dépasse la valeur maximale en temps $t_f$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
